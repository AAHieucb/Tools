Nginx


# Basic
Web server chỉ là 1 máy tính chạy phần mầm web server, cấu hình router mạng để public ra ngoài.
Web server tối thiểu phải serve được html. Apache, Nginx chuyên php; IIS của Microsoft dành cho asp, aspx; Sun Java system dành cho jsp

-> Forward Proxy: Đại diện cho người dùng truy cập các tài nguyên trên Internet. Nó ẩn danh người dùng, lọc nội dung or cache để tăng tốc độ. VD dùng CDN.
Reverse Proxy: Đại diện cho máy chủ nhận các request. Nó có thể cân bằng tải, mã hóa SSL. Nó giúp che giấu bảo mật cho máy chủ thực, response từ nó giống như là từ 1 máy chủ.

-> So sánh nginx apache
Apache chỉ nhận 1 lượng request xác định và loại bỏ số còn lại trong khi NGINX cố gắng hết khả năng để k bỏ qua 1 request nào. Nó có thể chịu được số lượng user lớn truy xuất đến file tĩnh or động 1 thời điểm nhiều hơn Apache.
Apache "prefork" thì mỗi request kể cả lấy tài nguyên tĩnh đều dùng 1 process riêng. Còn NGINX xử lý hướng sự kiện trong cùng 1 luồng async, 1 process xử lý nhiều request liên tục tuỳ lượng tài nguyên còn lại của hệ thống. Mỗi process gồm nhiều worker nhỏ hơn xử lý request và Worker Connections sẽ quản lý tât cả thread đó => giải quyết C10K

-> *Nginx làm web server: chặn DDoS, load balancer nhiều server, xử lý 10000 kết nối đồng thời mà chiếm ít bộ nhớ, mã hóa SSL, cache txt css ảnh tĩnh trả dữ liệu luôn mà k cần gọi server. 
=> NGINX thường dùng khi trang web có lưu lượng truy cập cao với nội dung tĩnh, có thể kết hợp Apache để tận dụng lợi thế xử lý nhanh, thiết lập số lượng lớn kết nối đồng thời:
Client <--> Front-end <--> Backend(Php,..) - Apache
                      <--> Static content(txt, js, css, images, video,..) - NGINX
Cloudflare chống DDoS tốt nên có thể dùng như 1 lớp reverse proxy trước nginx, cứ cần thêm cái gì thì add nó như 1 lớp reserve proxy forward liên tục tới đích là được.

-> Cài: download NGINX trên Mainline -> giải nén vào ổ C -> vào chạy file nginx.exe -> mở browser localhost -> tắt thì mở ctrl shift escape để end task.
Để chạy react với nginx: npm run build r nhét vào nginx html r chạy nginx như bth



# Config Nginx
URL search: https://viblo.asia/p/tim-hieu-va-huong-dan-setup-web-server-nginx-OREGwBwlvlN

-> Các module trong file:
- http: các chỉ thị và các khối từ tất cả cac module liên quan đến HTTP. Có thể tạo nhiều khối và các khối chỉ thị sau sẽ đè lên trước.
- server: khai báo 1 website (hostname) cụ thể được nhận diện bởi nginx và cấu hình của nó. Khối này nằm trong khối http, default là hostname localhost gửi lại file index.html
- upstream: xác định 1 nhóm các server
- location: định nghĩa các thiết lập áp dụng cho 1 vị trí cụ thể của URL website. Khối location có thể dùng trong khối server or nằm chồng trong 1 khối location khác
=> VD ta tạo khối http cấu hình web và bên trong có nhiều khối server, mỗi khối server ta định nghĩa các tên miền mà website có. Bên trong đó lại có nhiều khối location định nghĩa các uri khớp với 1 mẫu nào thì thiết lập cái gì

-> Các chỉ thị
--> Cấu hình HOST và SOCKET:
listen: dùng trong khối server, địa chỉ ip và port được dùng bởi socket phục vụ website. Thường là 80 cho http và 443 cho https. 
Cú pháp: listen [address] [:port] [additional options];
Các [additional options]:
- default hoặc default_server: chỉ rõ khối server này được dùng như website mặc định cho bất kỳ yêu cầu nhận được tại địa chỉ IP và port được chỉ rõ
- ssl: dùng SSL
- gửi lời gọi đến hệ thống bind và listen: backlog=num, rcvbuf=size, sndbuf=size, accept_filter=filter, deferred, setfib=number, và bind
VD: listen 192.168.1.1:80;
listen 443 ssl; # k có address tự hiểu localhost

server_name: dùng trong khối server để đăng ký 1 or nhiều hostname cho khối server. Khi nhận request, nó sẽ lấy khối server đầu tiên khớp với host trong phần header của request, k khớp thì Nginx chọn khối server đầu tiên khớp với thông số của listen như port 80 rồi ưu tiên khối đầu tiên có tùy chọn mặc định cho phép trên chỉ thị listen
server_name hostname1 [hostname2…];
VD: server_name *.website.com; # nhận tất cả các domain có đuôi là .website.com
server_name .website.com; # Kết hợp cả *.website.com và website.com
Có thể dùng chuỗi rỗng như 1 giá trị của chỉ thị để bắt tất cả các yêu cầu không có giá trị Host trong phần header, nhưng chỉ sau ít nhất 1 tên thông thường (hoặc “_”). VD: server_name abc.com “”;
server_name _ “”;
=> _ tức là mọi domain. 

Cấu hình HTTPS:
VD: server {
  listen 80 default_server;
  server_name _;
  return 301 https://$host$request_uri;
}
=> Return 301 thì browser hiểu là đổi đường dẫn vĩnh viễn về HTTPS. Nó sẽ redirect mọi truy vấn tới HTTPS cho mọi domain. Or ta có thể chỉ redirect 1 server nào đó. VD:
server {
  listen 80;
  server_name example.com;
  return 301 https://example.com$request_uri;
}

--> Cấu hình đường dẫn và tài liệu:
root: sử dụng trong khối server, http, location, if; định nghĩa tài liệu gốc, chứa các tập tin muốn gửi khách
Dùng cú pháp: root /path/resource/; Giá trị mặc định là html

--> Cấu hình các request từ client:
keepalive_requests: sử dụng trong khối server, http, location; xác định tối đa số lượng yêu cầu được phục vụ trên 1 kết nối keep-alive. Giá trị mặc định là 100
Dùng kiểu: keepalive_requests 100;

--> MIME types: Multipurpose Internet Mail Extensions là chuẩn mô tả định dạng của các loại tệp.
types: dùng trong khối server, http, location; giúp tạo ra mối tương quan giữa các loại MIME và các phần mở rộng tập tin. VD: 
types {
  text/html html;
  image/gif gif;
  image/jpeg jpg;
}

Khi xử lý 1 tệp sẽ check đuôi tệp để quyết định loại MIME. Rồi gửi loại type đó trong phần Content-Type của response, để báo trình duyệt cách xử lý tệp tin.
VD: loại MIME của tập tin là application/pdf thì browser sẽ dùng 1 plugin tương ứng với loại MIME đó để đọc mà k cần tải tập tin đó về.
Nginx có 1 file mime.types chứa sẵn các phần mở rộng tệp tin quan trọng thường dùng mà ta có thể bao hàm nội dung của nó vào file conf với: include mime.types; chứ k cần thêm thủ công từng type. Nếu phần mở rộng k tìm thấy sẽ dùng loại mặc định được ghi trong chỉ thị default_type.

--> Chỉ thị về giới hạn: limit_except, limit_rate 

--> Chỉ thị về xử lý tệp tin và bộ nhớ đệm: open_file_cache, disable_symlinks 

--> VD setting gzip cho static file giúp giảm thiểu cost IO và đường truyền.
http {
  gzip              on;
  gzip_http_version 1.0;
  gzip_types        text/plain
                    text/html
                    text/xml
                    text/css
                    application/xml
                    application/xhtml+xml
                    application/rss+xml
                    application/atom_xml
                    application/javascript
                    application/x-javascript
                    application/x-httpd-php;
  gzip_disable      "MSIE [1-6]\.";
  gzip_disable      "Mozilla/4";
  gzip_comp_level   1;
  gzip_proxied      any;
  gzip_vary         on;
  gzip_buffers      4 8k;
  gzip_min_length   1100;
}
Có thể setting cache control để cache static file để tối ưu.

--> Bth client tạo kết nối TCP tới server thì sau khi nhận response sẽ đóng kết nối, thêm keepalive vào upstream giúp giữ TCP connection để reuse cho requests sau. VD 1 user gửi nhiều requests để lấy cả static resource thì nên dùng:
upstream app {
  server 127.0.0.1:5000;
  keepalive 16;
}

-> Tool https://github.com/matsuu/kataribe giúp phát hiện bottleneck nhưng phải enable => uncomment phần log_format và access_log của file config



# NGINX làm Load Balancer
VD config trên máy 10.10.10.1 là:
upstream proserver {
  server 10.10.10.9:9002;
  server 10.10.10.10:9002;
} 
2 server 10.10.10.9 và 10.10.10.10 đang chạy ở cổng 9002. Rồi config để máy 10.10.10.1 đón ở cổng 9000:
server {
  proxy_buffering off;
  client_max_body_size 5M;
  listen 9000;
  location / {
    proxy_pass http://proserver;
  }
}
Chạy NGINX bằng lệnh sudo service nginx restart là done. Khi gửi request về 10.10.10.1 sẽ redirect vào 10.10.10.9 or 10.10.10.10

Có thể sửa config với tham số weight. VD:
upstream proserver {
  server 10.10.10.9:9002 weight=1;
  server 10.10.10.10:9002 weight=2;
} thì 10.10.10.10 xử lý lưu lượng truy cập gấp đôi 10.10.10.9

upstream backend {
  server backend1.example.com max_fails=3 fail_timeout=15s;
  server backend2.example.com;
}
backend1 mà failed request 3 lần liên tiếp sẽ bị đánh dấu là k khả dụng trong 15s tiếp theo, sau 15s nginx sẽ ping thử server, nếu vẫn k khả dụng sẽ lại down 15s và cứ thế.

-> Các routing method
Mặc định tự dùng round robin

upstream backend {
  ip_hash; # ip_hash đảm bảo request từ cùng 1 IP sẽ chuyển đến cùng 1 máy chủ backend, nếu máy chủ đó hỏng sẽ chuyển cho máy chủ khác.
  server backend1.example.com;
  server backend3.example.com down; # là flag đánh dấu 1 máy chủ đang k khả dụng
}

least_conn; # gửi tới server có số active connections ít nhất, tính cả trường weight.



# Dùng nginx chống DDoS
=> 1 số config chỉ có trên nginx plus, k dùng được trên nginx thường

--> DDoS thì lưu lượng truy cập lớn từ 1 tập các IP cố định vì hacker chỉ cần cho bot liên tục request tới server, 1 lượng đủ để áp đảo máy chủ. Việc sử dụng forward proxy cũng có biểu hiện tương tự nhưng lưu lượng vẫn thấp hơn nhiều so với các cuộc tấn công DDoS. 
Header User-Agent thường là 1 giá trị non-standard k chuẩn
Header Referer thường là 1 giá trị có thể liên kết với cuộc tấn công.

-> Trước tiên, nginx có kiến trúc non-blocking và event-driven vốn đã có thể xử lý 1 lượng request khổng lồ. Các yêu cầu mới không làm gián đoạn các phiên làm việc của nginx nên bản thân nó đã ngăn chặn các cuộc tấn công cơ bản.
Nginx có thể xử lý lượng request đồng thời tốt hơn các máy chủ cân bằng tải khác, do đó vẫn nên dùng thêm.

-> Giới hạn số lượng request 1 ip chỉ được gửi sau mỗi 2s.
limit_req_zone $binary_remote_addr zone=one:10m rate=30r/m;
server {
  # ...
  location /login.html {
    limit_req zone=one;
  # ...
  }
}
=> limit_req_zone định cấu hình 1 vùng nhớ chung gọi là one lưu trạng thái các request cho key là $binary_remote_addr (ip của máy khách). zone one lưu state của request từ 1 ip và giới hạn 30 request trong 1 phút. 
Mọi request tới server vào url /login.html sẽ dùng zone one

-> Giới hạn số lượng kết nối đến 1 vùng chỉ định của trang web
limit_conn_zone $binary_remote_addr zone=addr:10m;

server {
  # ...
  location /store/ {
    limit_conn addr 10;
    # ...
  }
}
=> limit_conn_zone định cấu hình 1 vùng nhớ chung là "addr" lưu các yêu cầu có key là ip của client là $binary_remote_addr. Ở đây nó limit 1 ip gọi tới vùng /store/ của trang web chỉ được max 10 connection thôi

-> Vì hacker có xu hướng dùng các kết nối ghi dữ liệu thường xuyên vì chúng muốn giữ connection càng lâu càng tốt, từ đó giảm khả năng của server trong việc chấp nhận các connection mới. Các connection chậm này có thể được chặn lại. Slowloris là 1 VD của kiểu tấn công này. 
server {
  client_body_timeout 5s;
  client_header_timeout 5s;
  # ...
}
=> client_body_timeout kiểm soát thời gian nginx đợi để nhận được body của client. client_header_timeout kiểm soát thời gian nginx đợi để nhận được header của client. 
Ở đây nếu quá 5s mà chưa nhận được, nginx sẽ đóng kết nối phiên hiện tại và cho rằng yêu cầu bị hủy bỏ và thực hiện xử lý khác. Vì nếu nginx đợi quá lâu sẽ giảm performance trong việc nhận connection mới

-> Chặn ip với nginx
location / {
  deny 123.123.123.0/28;
  # ...
}
=> Phải làm thủ công nếu check log thấy 1 ip là hacker DDoS

-> Trong 1 số TH ta chỉ dựng server cho 1 lượng ip cụ thể
location / {
  allow 192.168.1.0/24;
  deny all;
  # ...
}

-> Sử dụng caching trong nginx
Khi mà DDoS yêu cầu lặp lại nhiều lần, các data liên quan nên được lấy từ cache để giảm tải cho server thực

Trước tiên cấu hình 1 proxy cache:
proxy_cache_path /path/to/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m;
=> 1 proxy cache chạy tại url /path/to/cache với max dung lượng 10GB và thời gian hoạt động là 60p. Tham số levels xác định cấu trúc thư mục, ở đây cache được lưu dưới 1 thư mục cấp 1 và 1 thư mục cấp 2, cấu trúc như v giúp tăng hiệu suất khi truy cập cache.

Dùng proxy_cache_use để chỉ định khi nào cache nên được cập nhật:
location / {
  proxy_cache my_cache;
  proxy_cache_valid 200 302 10m;
  proxy_cache_use stale updating error timeout;
  proxy_pass http://backend;
}
=> Dùng cache tên là my_cache xác định khi khởi tạo. Thời gian hiệu lực của các response mã 200 và 302 là 10p, các phản hồi với mã khác sẽ k được lưu trong cache. 
Còn proxy_cache_use stale updating error timeout; xác định các tùy chọn sử dụng cache trong trường hợp cache không khả dụng or gặp sự cố:
- stale: sử dụng cache cũ nếu cache không có bản sao mới nhất của tài nguyên
- updating: sử dụng cache cũ trong quá trình cập nhật nếu cache vẫn đang được cập nhật bởi 1 yêu cầu khác
- error: vẫn sử dụng cache với yêu cầu lỗi và k thể nhận phản hồi từ server
- timeout: vẫn sử dụng cache nếu request timeout và k nhận phản hồi từ server backend

-> Chặn các yêu cầu tùy tình huống:

location /foo.php {
  deny all;
}
=> Sau khi cuộc tấn công DDoS nhắm vào /foo.php, mọi request vào nó nên được chặn lại. Ta có thể fix or chuyển sang 1 location khác.

location / {
  if ($http_user_agent ~* foo|bar) {
    return 403;
  }
  # ...
}
=> Header User-Agent có giá trị bất thường so với các truy cập hợp lệ khác có thể bị chặn. Tương tự với các request có header Referer

-> Giới hạn kết nối đến máy backend
upstream website {
  server 192.168.100.1:80 max_conns=200;
  server 192.168.100.2:80 max_conns=200;
  queue 10 timeout=30s;
}

-> Giới hạn kết nối tới backend server. Vì mục tiêu chống DDoS là cản được hacker và nếu có bị DDoS thì phải giới hạn 1 lượng để k sập server. 
upstream website {
  server 192.168.100.1:80 max_conns=200;
  server 192.168.100.2:80 max_conns=200;
  queue 10 timeout=30s;
}
=> Chỉ Nginx Plus mới dùng được max_conns. Ở đây ta giới hạn không quá 200 kết nối đến mỗi server backend đồng thời. Chỉ thị queue giới hạn lượng yêu cầu đợi khi mọi máy chủ trong nhóm upstream đạt max kết nối, timeout chỉ định thời gian 1 yêu cầu đợi. Ở đây quá 410 kết nối đồng thời sẽ từ chối, queue quá timeout cũng từ chối và pop khỏi queue.

Nginx Plus có thể nhận biết 1 cuộc tấn công DDoS thông qua Status or Dashboard, nó show số liệu và các mẫu lưu lượng bất thường, từ đó ta có thể thực hiện các actions cụ thể.



//!!!!!!!
# Config tiếp file nginx.conf
-> Dùng log trong nginx
--> Chỉ thị error_log: VD error_log log_file [ log_level ] => log_level là mức ghi log thấp nhất mà ta muốn ghi lại: debug, info, notice, warn, error, crit, alert, emerg. 
Khi chỉ định log_level, nó sẽ ghi log từ cấp độ đó đến cấp độ cao hơn cấp độ đó. K tin mở file log_file để thấy nó ghi lại những gì trong quá trình server chạy. Từ đó solve error

--> Nginx access log là 1 loại log khác giống error log nhưng nó sẽ ghi theo mỗi request mà client tạo ra. Dùng chỉ thị: access_log log_file log_format;
Tưng phần của log_format được xác định bằng biến bắt đầu bằng $. VD enabled nó để nó ghi các nút thắt cổ chai của server => nó sẽ ghi ra log các biến mà ta xác định trong cặp ""

VD log_format có định dạng combined thì kiểu:
log_format combined '$remote_addr - $remote_user [$time_local]  '
		    '"$request" $status $body_bytes_sent '
		    '"$http_referer" "$http_user_agent"'; 
=> danh sách các biến hỗ trợ: http://nginx.org/en/docs/http/ngx_http_core_module.html#variables
=> cũng có nhiều định dạng khác, không chỉ combined như main, compression

Chỉ thị access_log
access_log /path/to/log/location [ format_of_log buffer_size ];
format_of_log mặc định là combined. buffer_size là kích thước cache.
Có thể dùng: access_log location format gzip; để nén log file

Trên ubuntu có thể dùng cho error_log /dev/null crit; thì /dev/null là nơi để chọn thì error_log sẽ k ghi lại bất cứ thứ gì
Dùng access_log off; khi chạy vào các location lỗi là để tắt ghi log đi vì ta biết nó lỗi gì để xử lý r

--> Để tránh đầy dung lượng đĩa thì phải xoay log. Đó là việc chuyển đổi các file log và có thể lưu trữ file cũ trong 1 khoảng tg nhất định. Ta k thể quản lý file log trong nginx nhưng có thể xoay log được:
mv /path/to/access.log /path/to/access.log.0
kill -USR1 `cat /var/run/nginx.pid`
sleep 1
[ post-rotation processing of old log file ]
=> đầu tiên di chuyển log hiện tại sang 1 file mới để lưu trữ, có thể đặt nó là .0 và file cũ hơn là .1
=> lệnh kill -USR1 `cat /var/run/nginx.pid` sẽ gửi tín hiệu reload các file log khiến content được ghi vào file log được làm mới. Tệp nginx.pid là nơi nginx lưu trữ pid của quy trình chính. Điều này chỉ đúng trong linux
=> xoay vòng xong ta sleep 1 để hoàn tất, ta có thể nén file cũ or làm gì tùy ý.

Cách 2 để xoay vòng là dùng logrotate: nó là chương trình cài sẵn trên ubuntu và nginx trên ubuntu đi kèm với tập lệnh logrotate tùy chỉnh => kqtr

-> $uri là biến chỉ phần của url đăng sau domain name
VD1 TH gửi lại cho người dùng default GIF file nếu file k tồn tại:
location /images/ {
  try_files $uri $uri/ /images/default.gif;
}
location = /images/default.gif {
  expires 30s;
}
=> Người dùng request http://www.domain.com/images/image1.gif => nginx sẽ tìm image1.gif trong chỉ thị root or alias xác định từ trước, nếu k có nó sẽ tìm trong image1.gif/ và k tìm thấy sẽ lấy tiếp /images/default.gif => nó sẽ chạy sang chỉ thị location thứ 2 và dừng process, nginx sẽ lấy file đó và đánh dấu trong cache trong 30s 

VD2 try_files $uri =404; lấy $uri nếu k tồn tại sẽ trả 404

--> Cache trong nginx
Cấu hình HTTP Caching cho Nginx được áp dụng phổ biến trên tất cả trình duyệt web hiện đại. Ta sẽ dùng nó để cải thiện thời gian phản hồi về client và giảm tải các request cho máy chủ. Nếu cấu hình k chính xác thì người dùng có thể nhận về nội dung cũ và khó fix bug. HTTP caching xảy ra khi trình duyệt nó tự lưu lại bản sao của tài nguyên trong cache để k phải xử lý request lại từ đầu. 
Thực hiện điều này sẽ giúp website tăng performance lên nhiều so với để server mặc định của nginx
Xử lý phải có kỹ thuật: client request file app.js -> server gửi lại cho client -> 2p sau client lại cần file app.js -> server check file đó k có gì thay đổi -> client lấy từ cache của trình duyệt => thực tế ta phải cấu hình nginx sao cho client k cần gửi thêm bất cứ request nào lên server nx mà vẫn có file app.js mà k sợ nó đã bị cũ trên server.

- Giải pháp 1: Weak Caching Header(Etag / Last-Modified) phải request lên server để check sự thay đổi của các tài nguyên
1.1> Last-Modified => Lần đầu tiên thì server gửi file logo.png kèm tham số last-modified ở response là thời điểm cuối cùng thay đổi của file. Lần tiếp theo request client có thêm If-Modified-Since là giá trị của them số Last-Modified lần trước nhận dược, server check nếu trùng với thời gian thay đổi lần cuối trên server thì trả lại 304 Not Modified để báo cho client biết file này éo đổi gì cả, client sẽ lấy bản sao được lưu cache browser
1.2> Etag => Tương tự nhưng dùng chuỗi ký tự để check sự thay đổi của file thông qua request header If-None-Match và response Header Etag chứ éo nhất thiết phải là 1 mốc tg. Thực tế, server k lưu lại giá trị Etag để lôi ra check như là Last-Modified mà nó dùng thuật toán để tính ra Etag trong spec của HTTP, điều này giúp server hạn chế update Etag mỗi lần file đổi
- Giải pháp 2: Strong Caching Header(Expires / Cache-Control) k cần request lên server nx
2.1> Expires => xác định thời gian hết hạn của file. Khi cần lấy file, client check nó hết hạn chưa, nếu chưa sẽ lấy trong cache trình duyệt. VD: expires 5m; => file hết hạn trong 5p mặc kệ client có request lên server k
2.2> Cache-Control => thêm các option sau expires trong file cấu hình:
no-store => file luôn được trả về theo cách thông thường, k lưu trong cache trình duyệt
no-cache => cache sẽ gửi yêu cầu đến máy chủ để xác thực r mới tiến hành sao chép lưu trong trình duyệt(cache but revalidate)
private/public => public cho phép file được cache bởi các proxy và server trung gian; private thì browser có thể cache nhưng proxy thì k, chỉ cho phép file có giá trị khác nhau cho các client khác nhau.
max-age=12355 => thời gian tối đa mà tài nguyên còn hạn sử dụng với cache
must-revalidate => buộc client phải validate với server trước khi sử dụng các file đã được caching

Còn giải pháp khác như Laravel mix để đánh dấu sự thay đổi của file ngay trong tên file. VD: A.123456.js or a.js?v=123456 làm tên cho file nhưng kp lúc nào cx dùng được.

Khi dùng 1 trong 4 giải pháp chú ý lỗi. VD: ta đặt expires sau 5p nhưng file bị đổi trước đó dẫn đến người dùng nhận lại tài nguyên cũ -> bug => ta nên kết hợp linh hoạt khi mà weak thì tốc độ cao, strong thì lâu hơn nhưng an toàn => các file js, css là những file thường xuyên thay đổi nên dùng giải pháp Etag; các file ảnh, font chữ là file ít đổi nên dùng expires 5p.
Thực tế các server config mặc định là dùng etag caching cho tất cả file nên ta phải sửa lại VD file config của nginx:
 server {
   listen 80;
   server_name xxxxx; // Thông số đã được ẩn đi ahihi
   root xxxxx; // Thông số đã được ẩn đi

   add_header X-Frame-Options "SAMEORIGIN";
   add_header X-XSS-Protection "1; mode=block";
   add_header X-Content-Type-Options "nosniff";

   index index.html index.htm index.php;

   charset utf-8;

   location / {
      try_files $uri $uri/ /index.php?$query_string;
   }

   location ~ \.php$ {
      fastcgi_pass unix:/var/run/php/php7.2-fpm.sock;
      fastcgi_index index.php;
      fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;
      include fastcgi_params;
   }

   location ~* \.(?:css|js)$ {
      access_log        off;
      log_not_found     off;

      etag on; // Bật chế độ cache Etag
   }

   location ~* \.(?:jpg|jpeg|gif|png|ico|xml)$ {
      access_log        off;
      log_not_found     off;
  
      expires           5m; // Bật chế độ cache expires
      add_header        Cache-Control "public"; // Caching cả cho proxy
   }
 

   location ~* \.(?:eot|woff|woff2|ttf|svg|otf) {
      access_log        off;
      log_not_found     off;

      expires           5m;  // Bật chế độ cache expires
      add_header        Cache-Control "public"; // Caching cả cho proxy
      add_header        Access-Control-Allow-Origin *;

      types     {font/opentype otf;}
      types     {application/vnd.ms-fontobject eot;}
      types     {font/truetype ttf;}
      types     {application/font-woff woff;}
      types     {font/x-woff woff2;}
   }

   location ~ /\. { 
      access_log        off; 
      log_not_found     off; 
      deny              all; 
   }
}



# Dùng docker với nginx
-> Nó dùng 1 image là alpine cũng là 1 nền tảng linux xd dựa trên busybox mang tính bảo mật, đơn giản và hiệu suất tài nguyên hợp lý. Nó như 1 bản phân phối đầy đủ tính năng của Linux 
RUN apk add --no-cache git => apk add <tên gói> để cài 1 gói mới vào alpine với --no-cache là k cache ở command build image. Đây là lệnh của nền tảng alpine
RUN npm install --production --silient => npm install là cài các package nhưng --production tức nó bỏ qua các package trong devDependencies
--silient hình như à silent mới đúng tức k log output trong quá trình install
RUN npm run build sẽ chạy react-scripts build => nên nhớ trong 1 dự án react có 2 môi trường và development thì dùng react-scripts start, còn production thì react-scripts build

Thực tế nó có đến 4 môi trường là dev, test, staging, production cơ
Tải image nginx và copy config vào đúng thư mục trong docker. Copy đúng thư mục build nx mà khi chạy npm run build mới sinh ra
RUN mặc định nginx ở foreground với daemon off => nginx k thôi thì sẽ chạy trong background
=> Là ta đã chạy được dự án với server nginx 
File .dockerignore sẽ bỏ qua cac thành phần k cần thiết vào image trong quá trình build
Nhớ chuyển buildkit: false trong setting của docker desktop để chạy được docker build . --tag trava-knight-nft-ui nếu bị lỗi thì thêm option
docker build . --network host --tag trava-knight-nft-ui => nhưng rất tiếc option ấy éo hoạt động trên window 

-> Khi dùng docker, ta k nên copy cả node_modules r bỏ npm install trong Dockerfile vì thực tế các nền tảng khác nhau nó sẽ cài các dependencies khác nhau nên chạy v dễ báo lỗi. Ta luôn để ignore node_modules ở môi trường ngoài và chạy npm install ở Dockerfile để tránh lỗi đó

Để tối ưu khi chạy trên Docker phải can thiệp vào nhiều thứ như dockerignore, docker layer, layer caching, multistage build trong docker,... Có các bài riêng giảng về nó có thể tối ưu hàng trăm GB


